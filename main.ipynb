{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras import models, layers, activations, optimizers, utils, losses, initializers, metrics, callbacks\n",
    "import numpy as np \n",
    "import cv2 as cv \n",
    "import matplotlib as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 32\n",
    "patience = 25\n",
    "learning_rate = 0.001\n",
    "model_path = 'checkpoints/model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resizing (Resizing)         (None, 30, 30, 3)         0         \n",
      "                                                                 \n",
      " rescaling (Rescaling)       (None, 30, 30, 3)         0         \n",
      "                                                                 \n",
      " random_rotation (RandomRot  (None, 30, 30, 3)         0         \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 28, 28, 64)        1792      \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 28, 28, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 14, 14, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 6, 6, 64)          256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 2304)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               295040    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 62)                31806     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596222 (2.27 MB)\n",
      "Trainable params: 596094 (2.27 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "exists = os.path.exists(model_path)\n",
    "\n",
    "model = models.load_model(model_path) \\\n",
    "    if exists \\\n",
    "        else models.Sequential([\n",
    "            layers.Resizing(30, 30),\n",
    "            layers.Rescaling(scale=1./127.5, offset=-1),\n",
    "            layers.RandomRotation((-0.2, 0.2)),\n",
    "            layers.Conv2D(64, (3, 3),\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(64, (3, 3),\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(128,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(256,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dense(62,\n",
    "                activation = 'sigmoid',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "if exists:\n",
    "    model.summary()\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer = optimizers.Adam(\n",
    "        learning_rate = learning_rate\n",
    "        ),\n",
    "        loss = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics = [ 'accuracy' ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3410 files belonging to 62 classes.\n",
      "Using 2728 files for training.\n",
      "Found 3410 files belonging to 62 classes.\n",
      "Using 682 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train = utils.image_dataset_from_directory(\n",
    "    \"Img\", # Change path\n",
    "    validation_split= 0.2,\n",
    "    subset= \"training\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (128, 128),\n",
    "    batch_size= batch_size\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    \"Img\", # Change path\n",
    "    validation_split= 0.2,\n",
    "    subset= \"validation\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (128, 128),\n",
    "    batch_size= batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/86 [==============================] - 5s 36ms/step - loss: 3.1916 - accuracy: 0.1239 - val_loss: 3.0740 - val_accuracy: 0.1173\n",
      "Epoch 2/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 3.1226 - accuracy: 0.1375 - val_loss: 3.7200 - val_accuracy: 0.0865\n",
      "Epoch 3/100\n",
      "86/86 [==============================] - 3s 35ms/step - loss: 3.1631 - accuracy: 0.1367 - val_loss: 3.4372 - val_accuracy: 0.0997\n",
      "Epoch 4/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 3.1160 - accuracy: 0.1327 - val_loss: 3.2175 - val_accuracy: 0.1261\n",
      "Epoch 5/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 3.1273 - accuracy: 0.1272 - val_loss: 3.1100 - val_accuracy: 0.1217\n",
      "Epoch 6/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 3.1444 - accuracy: 0.1331 - val_loss: 3.0213 - val_accuracy: 0.1540\n",
      "Epoch 7/100\n",
      "86/86 [==============================] - 3s 33ms/step - loss: 3.1313 - accuracy: 0.1397 - val_loss: 3.2341 - val_accuracy: 0.1026\n",
      "Epoch 8/100\n",
      "86/86 [==============================] - 3s 32ms/step - loss: 3.1196 - accuracy: 0.1338 - val_loss: 2.9473 - val_accuracy: 0.1906\n",
      "Epoch 9/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 3.1145 - accuracy: 0.1404 - val_loss: 3.4531 - val_accuracy: 0.0821\n",
      "Epoch 10/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 3.0853 - accuracy: 0.1496 - val_loss: 3.0013 - val_accuracy: 0.1540\n",
      "Epoch 11/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 3.1212 - accuracy: 0.1375 - val_loss: 2.9677 - val_accuracy: 0.1466\n",
      "Epoch 12/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 3.0751 - accuracy: 0.1444 - val_loss: 3.1883 - val_accuracy: 0.1129\n",
      "Epoch 13/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 3.0953 - accuracy: 0.1525 - val_loss: 3.3517 - val_accuracy: 0.1320\n",
      "Epoch 14/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 3.0939 - accuracy: 0.1393 - val_loss: 3.3557 - val_accuracy: 0.1334\n",
      "Epoch 15/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 3.0881 - accuracy: 0.1419 - val_loss: 3.1439 - val_accuracy: 0.1276\n",
      "Epoch 16/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 3.0476 - accuracy: 0.1554 - val_loss: 3.0491 - val_accuracy: 0.1349\n",
      "Epoch 17/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0814 - accuracy: 0.1543 - val_loss: 2.8500 - val_accuracy: 0.1994\n",
      "Epoch 18/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 3.0658 - accuracy: 0.1573 - val_loss: 2.8031 - val_accuracy: 0.2097\n",
      "Epoch 19/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0772 - accuracy: 0.1419 - val_loss: 3.2156 - val_accuracy: 0.1202\n",
      "Epoch 20/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0668 - accuracy: 0.1510 - val_loss: 3.2748 - val_accuracy: 0.1305\n",
      "Epoch 21/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 3.0395 - accuracy: 0.1547 - val_loss: 2.7710 - val_accuracy: 0.1906\n",
      "Epoch 22/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0379 - accuracy: 0.1481 - val_loss: 2.7470 - val_accuracy: 0.2009\n",
      "Epoch 23/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0122 - accuracy: 0.1499 - val_loss: 2.8617 - val_accuracy: 0.1833\n",
      "Epoch 24/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 3.0187 - accuracy: 0.1554 - val_loss: 2.8367 - val_accuracy: 0.1935\n",
      "Epoch 25/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 3.0393 - accuracy: 0.1507 - val_loss: 2.7870 - val_accuracy: 0.2141\n",
      "Epoch 26/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 3.0016 - accuracy: 0.1485 - val_loss: 2.7134 - val_accuracy: 0.2199\n",
      "Epoch 27/100\n",
      "86/86 [==============================] - 4s 41ms/step - loss: 3.0129 - accuracy: 0.1661 - val_loss: 3.1851 - val_accuracy: 0.1393\n",
      "Epoch 28/100\n",
      "86/86 [==============================] - 4s 42ms/step - loss: 2.9942 - accuracy: 0.1580 - val_loss: 3.5048 - val_accuracy: 0.1012\n",
      "Epoch 29/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0010 - accuracy: 0.1584 - val_loss: 3.6234 - val_accuracy: 0.0953\n",
      "Epoch 30/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 3.0411 - accuracy: 0.1536 - val_loss: 2.9995 - val_accuracy: 0.1584\n",
      "Epoch 31/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9911 - accuracy: 0.1532 - val_loss: 2.7343 - val_accuracy: 0.2287\n",
      "Epoch 32/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 3.0037 - accuracy: 0.1620 - val_loss: 3.0962 - val_accuracy: 0.1378\n",
      "Epoch 33/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9840 - accuracy: 0.1617 - val_loss: 2.6979 - val_accuracy: 0.2434\n",
      "Epoch 34/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 2.9415 - accuracy: 0.1745 - val_loss: 3.0828 - val_accuracy: 0.1452\n",
      "Epoch 35/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9621 - accuracy: 0.1844 - val_loss: 3.7302 - val_accuracy: 0.0953\n",
      "Epoch 36/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9566 - accuracy: 0.1767 - val_loss: 3.0331 - val_accuracy: 0.1569\n",
      "Epoch 37/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.9735 - accuracy: 0.1672 - val_loss: 2.8157 - val_accuracy: 0.1891\n",
      "Epoch 38/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9683 - accuracy: 0.1727 - val_loss: 3.0745 - val_accuracy: 0.1584\n",
      "Epoch 39/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.9472 - accuracy: 0.1675 - val_loss: 3.3514 - val_accuracy: 0.1334\n",
      "Epoch 40/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.9583 - accuracy: 0.1595 - val_loss: 2.8151 - val_accuracy: 0.1950\n",
      "Epoch 41/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9406 - accuracy: 0.1756 - val_loss: 3.0911 - val_accuracy: 0.1496\n",
      "Epoch 42/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.9533 - accuracy: 0.1705 - val_loss: 2.9094 - val_accuracy: 0.2023\n",
      "Epoch 43/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.9630 - accuracy: 0.1697 - val_loss: 2.7276 - val_accuracy: 0.1891\n",
      "Epoch 44/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.9076 - accuracy: 0.1804 - val_loss: 3.1013 - val_accuracy: 0.1466\n",
      "Epoch 45/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8712 - accuracy: 0.1891 - val_loss: 4.1185 - val_accuracy: 0.1041\n",
      "Epoch 46/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.9218 - accuracy: 0.1804 - val_loss: 2.7669 - val_accuracy: 0.2199\n",
      "Epoch 47/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.9009 - accuracy: 0.1848 - val_loss: 2.8203 - val_accuracy: 0.1789\n",
      "Epoch 48/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8844 - accuracy: 0.1804 - val_loss: 2.6022 - val_accuracy: 0.2419\n",
      "Epoch 49/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.9272 - accuracy: 0.1686 - val_loss: 2.5588 - val_accuracy: 0.2361\n",
      "Epoch 50/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.9173 - accuracy: 0.1895 - val_loss: 2.6339 - val_accuracy: 0.2317\n",
      "Epoch 51/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8704 - accuracy: 0.1778 - val_loss: 2.6022 - val_accuracy: 0.2610\n",
      "Epoch 52/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8878 - accuracy: 0.1767 - val_loss: 2.6187 - val_accuracy: 0.2390\n",
      "Epoch 53/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8752 - accuracy: 0.1796 - val_loss: 2.7328 - val_accuracy: 0.2639\n",
      "Epoch 54/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8664 - accuracy: 0.1873 - val_loss: 2.6231 - val_accuracy: 0.2111\n",
      "Epoch 55/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 2.8646 - accuracy: 0.1884 - val_loss: 2.7641 - val_accuracy: 0.1921\n",
      "Epoch 56/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.8520 - accuracy: 0.1935 - val_loss: 2.7548 - val_accuracy: 0.1716\n",
      "Epoch 57/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8761 - accuracy: 0.1840 - val_loss: 2.6293 - val_accuracy: 0.2287\n",
      "Epoch 58/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8631 - accuracy: 0.2042 - val_loss: 2.5539 - val_accuracy: 0.2757\n",
      "Epoch 59/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8387 - accuracy: 0.1902 - val_loss: 2.4816 - val_accuracy: 0.2595\n",
      "Epoch 60/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.8303 - accuracy: 0.1957 - val_loss: 3.3402 - val_accuracy: 0.0938\n",
      "Epoch 61/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 2.8501 - accuracy: 0.1968 - val_loss: 2.9752 - val_accuracy: 0.1540\n",
      "Epoch 62/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8599 - accuracy: 0.1884 - val_loss: 2.6051 - val_accuracy: 0.2786\n",
      "Epoch 63/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8139 - accuracy: 0.1910 - val_loss: 3.2582 - val_accuracy: 0.1833\n",
      "Epoch 64/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8302 - accuracy: 0.2133 - val_loss: 2.9849 - val_accuracy: 0.1906\n",
      "Epoch 65/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8288 - accuracy: 0.1884 - val_loss: 2.5546 - val_accuracy: 0.2478\n",
      "Epoch 66/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.8541 - accuracy: 0.1917 - val_loss: 2.8042 - val_accuracy: 0.1877\n",
      "Epoch 67/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8098 - accuracy: 0.2104 - val_loss: 2.5683 - val_accuracy: 0.2302\n",
      "Epoch 68/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.8017 - accuracy: 0.2020 - val_loss: 2.5033 - val_accuracy: 0.2302\n",
      "Epoch 69/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.8037 - accuracy: 0.2001 - val_loss: 2.4273 - val_accuracy: 0.2757\n",
      "Epoch 70/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7927 - accuracy: 0.2031 - val_loss: 2.6285 - val_accuracy: 0.2229\n",
      "Epoch 71/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7860 - accuracy: 0.2144 - val_loss: 2.5278 - val_accuracy: 0.2463\n",
      "Epoch 72/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 2.7960 - accuracy: 0.2064 - val_loss: 2.6575 - val_accuracy: 0.2097\n",
      "Epoch 73/100\n",
      "86/86 [==============================] - 4s 39ms/step - loss: 2.7645 - accuracy: 0.2064 - val_loss: 2.5620 - val_accuracy: 0.2434\n",
      "Epoch 74/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7584 - accuracy: 0.2122 - val_loss: 2.5126 - val_accuracy: 0.2566\n",
      "Epoch 75/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7892 - accuracy: 0.1979 - val_loss: 2.3978 - val_accuracy: 0.3050\n",
      "Epoch 76/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7548 - accuracy: 0.2174 - val_loss: 2.3362 - val_accuracy: 0.2947\n",
      "Epoch 77/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7783 - accuracy: 0.1983 - val_loss: 2.5153 - val_accuracy: 0.2287\n",
      "Epoch 78/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7268 - accuracy: 0.2232 - val_loss: 3.8999 - val_accuracy: 0.1041\n",
      "Epoch 79/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7579 - accuracy: 0.2148 - val_loss: 2.5952 - val_accuracy: 0.1994\n",
      "Epoch 80/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7586 - accuracy: 0.2144 - val_loss: 2.5968 - val_accuracy: 0.2346\n",
      "Epoch 81/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7503 - accuracy: 0.2192 - val_loss: 2.6094 - val_accuracy: 0.2097\n",
      "Epoch 82/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7365 - accuracy: 0.2126 - val_loss: 3.1123 - val_accuracy: 0.1701\n",
      "Epoch 83/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7540 - accuracy: 0.2203 - val_loss: 2.8724 - val_accuracy: 0.1877\n",
      "Epoch 84/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7869 - accuracy: 0.2056 - val_loss: 2.2732 - val_accuracy: 0.3211\n",
      "Epoch 85/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7550 - accuracy: 0.2078 - val_loss: 2.7935 - val_accuracy: 0.1877\n",
      "Epoch 86/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7357 - accuracy: 0.2159 - val_loss: 4.0653 - val_accuracy: 0.0924\n",
      "Epoch 87/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7036 - accuracy: 0.2199 - val_loss: 2.6082 - val_accuracy: 0.2434\n",
      "Epoch 88/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7212 - accuracy: 0.2221 - val_loss: 2.2858 - val_accuracy: 0.3123\n",
      "Epoch 89/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7182 - accuracy: 0.2192 - val_loss: 3.7578 - val_accuracy: 0.1320\n",
      "Epoch 90/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.7469 - accuracy: 0.2188 - val_loss: 2.4213 - val_accuracy: 0.3050\n",
      "Epoch 91/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.6972 - accuracy: 0.2254 - val_loss: 2.6466 - val_accuracy: 0.2405\n",
      "Epoch 92/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7454 - accuracy: 0.2181 - val_loss: 2.5708 - val_accuracy: 0.2478\n",
      "Epoch 93/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.6768 - accuracy: 0.2185 - val_loss: 2.7158 - val_accuracy: 0.2023\n",
      "Epoch 94/100\n",
      "86/86 [==============================] - 3s 38ms/step - loss: 2.6688 - accuracy: 0.2295 - val_loss: 2.6178 - val_accuracy: 0.2199\n",
      "Epoch 95/100\n",
      "86/86 [==============================] - 4s 40ms/step - loss: 2.6779 - accuracy: 0.2192 - val_loss: 2.2298 - val_accuracy: 0.3328\n",
      "Epoch 96/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.6822 - accuracy: 0.2232 - val_loss: 2.4651 - val_accuracy: 0.2933\n",
      "Epoch 97/100\n",
      "86/86 [==============================] - 3s 37ms/step - loss: 2.7033 - accuracy: 0.2335 - val_loss: 2.9060 - val_accuracy: 0.1833\n",
      "Epoch 98/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.7069 - accuracy: 0.2243 - val_loss: 2.4493 - val_accuracy: 0.2801\n",
      "Epoch 99/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.6962 - accuracy: 0.2265 - val_loss: 2.6724 - val_accuracy: 0.2405\n",
      "Epoch 100/100\n",
      "86/86 [==============================] - 3s 36ms/step - loss: 2.6972 - accuracy: 0.2236 - val_loss: 2.2874 - val_accuracy: 0.3050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19547279250>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,\n",
    "    epochs = epochs,\n",
    "    validation_data = test,\n",
    "    callbacks= [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = 1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath = model_path,\n",
    "            save_weights_only = False,\n",
    "            monitor = 'loss',\n",
    "            mode = 'min',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
