{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras import models, layers, activations, optimizers, utils, losses, initializers, metrics, callbacks\n",
    "import numpy as np \n",
    "import cv2 as cv \n",
    "import matplotlib as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 128\n",
    "patience = 100\n",
    "learning_rate = 0.001\n",
    "model_path = 'checkpoints/model.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exists = os.path.exists(model_path)\n",
    "\n",
    "model = models.load_model(model_path) \\\n",
    "    if exists \\\n",
    "        else models.Sequential([\n",
    "            layers.Resizing(25, 25),\n",
    "            layers.Rescaling(scale=1./127.5, offset=-1),\n",
    "            layers.Conv2D(256, (3, 3),\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.Conv2D(256, (3, 3),\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.MaxPooling2D((2, 2)),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.Flatten(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(512,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(1024,\n",
    "                activation = 'relu',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            ),\n",
    "            layers.Dense(62,\n",
    "                activation = 'sigmoid',\n",
    "                kernel_initializer = initializers.RandomNormal()\n",
    "            )\n",
    "        ])\n",
    "\n",
    "if exists:\n",
    "    model.summary()\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer = optimizers.Adam(\n",
    "        learning_rate = learning_rate\n",
    "        ),\n",
    "        loss = losses.SparseCategoricalCrossentropy(),\n",
    "        metrics = [ 'accuracy' ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61938 files belonging to 62 classes.\n",
      "Using 49551 files for training.\n",
      "Found 61938 files belonging to 62 classes.\n",
      "Using 12387 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train = utils.image_dataset_from_directory(\n",
    "    \"Img\",\n",
    "    validation_split= 0.2,\n",
    "    subset= \"training\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (128, 128),\n",
    "    batch_size= batch_size\n",
    ")\n",
    "\n",
    "test = utils.image_dataset_from_directory(\n",
    "    \"Img\",\n",
    "    validation_split= 0.2,\n",
    "    subset= \"validation\",\n",
    "    seed= 123,\n",
    "    shuffle= True,\n",
    "    image_size= (128, 128),\n",
    "    batch_size= batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\disrct\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "388/388 [==============================] - 73s 184ms/step - loss: 2.4006 - accuracy: 0.4097 - val_loss: 0.6748 - val_accuracy: 0.7708\n",
      "Epoch 2/1000\n",
      "388/388 [==============================] - 72s 186ms/step - loss: 1.0093 - accuracy: 0.6728 - val_loss: 0.4200 - val_accuracy: 0.8433\n",
      "Epoch 3/1000\n",
      "388/388 [==============================] - 78s 201ms/step - loss: 0.6965 - accuracy: 0.7607 - val_loss: 0.3018 - val_accuracy: 0.8842\n",
      "Epoch 4/1000\n",
      "388/388 [==============================] - 74s 189ms/step - loss: 0.5645 - accuracy: 0.7994 - val_loss: 0.2715 - val_accuracy: 0.8844\n",
      "Epoch 5/1000\n",
      "388/388 [==============================] - 72s 185ms/step - loss: 0.4846 - accuracy: 0.8217 - val_loss: 0.2297 - val_accuracy: 0.9045\n",
      "Epoch 6/1000\n",
      "388/388 [==============================] - 72s 185ms/step - loss: 0.4168 - accuracy: 0.8459 - val_loss: 0.2008 - val_accuracy: 0.9171\n",
      "Epoch 7/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.3943 - accuracy: 0.8512 - val_loss: 0.1918 - val_accuracy: 0.9175\n",
      "Epoch 8/1000\n",
      "388/388 [==============================] - 72s 184ms/step - loss: 0.3665 - accuracy: 0.8611 - val_loss: 0.1871 - val_accuracy: 0.9196\n",
      "Epoch 9/1000\n",
      "388/388 [==============================] - 70s 180ms/step - loss: 0.3434 - accuracy: 0.8682 - val_loss: 0.1784 - val_accuracy: 0.9228\n",
      "Epoch 10/1000\n",
      "388/388 [==============================] - 70s 180ms/step - loss: 0.3276 - accuracy: 0.8762 - val_loss: 0.1736 - val_accuracy: 0.9249\n",
      "Epoch 11/1000\n",
      "388/388 [==============================] - 72s 186ms/step - loss: 0.3161 - accuracy: 0.8798 - val_loss: 0.1542 - val_accuracy: 0.9371\n",
      "Epoch 12/1000\n",
      "388/388 [==============================] - 74s 189ms/step - loss: 0.2982 - accuracy: 0.8871 - val_loss: 0.1527 - val_accuracy: 0.9353\n",
      "Epoch 13/1000\n",
      "388/388 [==============================] - 72s 186ms/step - loss: 0.3005 - accuracy: 0.8868 - val_loss: 0.1542 - val_accuracy: 0.9350\n",
      "Epoch 14/1000\n",
      "388/388 [==============================] - 74s 191ms/step - loss: 0.2806 - accuracy: 0.8962 - val_loss: 0.1459 - val_accuracy: 0.9374\n",
      "Epoch 15/1000\n",
      "388/388 [==============================] - 73s 188ms/step - loss: 0.2643 - accuracy: 0.9004 - val_loss: 0.1382 - val_accuracy: 0.9393\n",
      "Epoch 16/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.2689 - accuracy: 0.9004 - val_loss: 0.1419 - val_accuracy: 0.9373\n",
      "Epoch 17/1000\n",
      "388/388 [==============================] - 73s 189ms/step - loss: 0.2571 - accuracy: 0.9033 - val_loss: 0.1379 - val_accuracy: 0.9393\n",
      "Epoch 18/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.2483 - accuracy: 0.9070 - val_loss: 0.1221 - val_accuracy: 0.9466\n",
      "Epoch 19/1000\n",
      "388/388 [==============================] - 72s 186ms/step - loss: 0.2514 - accuracy: 0.9079 - val_loss: 0.1217 - val_accuracy: 0.9500\n",
      "Epoch 20/1000\n",
      "388/388 [==============================] - 78s 200ms/step - loss: 0.2317 - accuracy: 0.9139 - val_loss: 0.1102 - val_accuracy: 0.9550\n",
      "Epoch 21/1000\n",
      "388/388 [==============================] - 71s 183ms/step - loss: 0.2252 - accuracy: 0.9175 - val_loss: 0.1159 - val_accuracy: 0.9499\n",
      "Epoch 22/1000\n",
      "388/388 [==============================] - 68s 174ms/step - loss: 0.2258 - accuracy: 0.9169 - val_loss: 0.1163 - val_accuracy: 0.9491\n",
      "Epoch 23/1000\n",
      "388/388 [==============================] - 75s 192ms/step - loss: 0.2188 - accuracy: 0.9212 - val_loss: 0.1014 - val_accuracy: 0.9558\n",
      "Epoch 24/1000\n",
      "388/388 [==============================] - 71s 182ms/step - loss: 0.2158 - accuracy: 0.9207 - val_loss: 0.1046 - val_accuracy: 0.9562\n",
      "Epoch 25/1000\n",
      "388/388 [==============================] - 71s 182ms/step - loss: 0.2055 - accuracy: 0.9244 - val_loss: 0.0982 - val_accuracy: 0.9564\n",
      "Epoch 26/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.2016 - accuracy: 0.9255 - val_loss: 0.1051 - val_accuracy: 0.9541\n",
      "Epoch 27/1000\n",
      "388/388 [==============================] - 73s 188ms/step - loss: 0.2027 - accuracy: 0.9268 - val_loss: 0.0949 - val_accuracy: 0.9595\n",
      "Epoch 28/1000\n",
      "388/388 [==============================] - 71s 183ms/step - loss: 0.1900 - accuracy: 0.9309 - val_loss: 0.0966 - val_accuracy: 0.9608\n",
      "Epoch 29/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1882 - accuracy: 0.9314 - val_loss: 0.0907 - val_accuracy: 0.9621\n",
      "Epoch 30/1000\n",
      "388/388 [==============================] - 71s 183ms/step - loss: 0.1815 - accuracy: 0.9339 - val_loss: 0.0858 - val_accuracy: 0.9651\n",
      "Epoch 31/1000\n",
      "388/388 [==============================] - 73s 188ms/step - loss: 0.1765 - accuracy: 0.9359 - val_loss: 0.0859 - val_accuracy: 0.9630\n",
      "Epoch 32/1000\n",
      "388/388 [==============================] - 71s 183ms/step - loss: 0.1805 - accuracy: 0.9346 - val_loss: 0.0806 - val_accuracy: 0.9667\n",
      "Epoch 33/1000\n",
      "388/388 [==============================] - 76s 194ms/step - loss: 0.1740 - accuracy: 0.9372 - val_loss: 0.0760 - val_accuracy: 0.9684\n",
      "Epoch 34/1000\n",
      "388/388 [==============================] - 74s 190ms/step - loss: 0.1686 - accuracy: 0.9390 - val_loss: 0.0781 - val_accuracy: 0.9669\n",
      "Epoch 35/1000\n",
      "388/388 [==============================] - 73s 189ms/step - loss: 0.1708 - accuracy: 0.9393 - val_loss: 0.0761 - val_accuracy: 0.9699\n",
      "Epoch 36/1000\n",
      "388/388 [==============================] - 69s 178ms/step - loss: 0.1667 - accuracy: 0.9413 - val_loss: 0.1645 - val_accuracy: 0.9381\n",
      "Epoch 37/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.1657 - accuracy: 0.9405 - val_loss: 0.0742 - val_accuracy: 0.9692\n",
      "Epoch 38/1000\n",
      "388/388 [==============================] - 69s 176ms/step - loss: 0.1679 - accuracy: 0.9414 - val_loss: 0.0759 - val_accuracy: 0.9663\n",
      "Epoch 39/1000\n",
      "388/388 [==============================] - 75s 193ms/step - loss: 0.1631 - accuracy: 0.9433 - val_loss: 0.0715 - val_accuracy: 0.9698\n",
      "Epoch 40/1000\n",
      "388/388 [==============================] - 71s 182ms/step - loss: 0.1527 - accuracy: 0.9456 - val_loss: 0.0693 - val_accuracy: 0.9726\n",
      "Epoch 41/1000\n",
      "388/388 [==============================] - 72s 184ms/step - loss: 0.1530 - accuracy: 0.9472 - val_loss: 0.0702 - val_accuracy: 0.9725\n",
      "Epoch 42/1000\n",
      "388/388 [==============================] - 76s 194ms/step - loss: 0.1405 - accuracy: 0.9491 - val_loss: 0.0643 - val_accuracy: 0.9734\n",
      "Epoch 43/1000\n",
      "388/388 [==============================] - 77s 198ms/step - loss: 0.1501 - accuracy: 0.9471 - val_loss: 0.0664 - val_accuracy: 0.9747\n",
      "Epoch 44/1000\n",
      "388/388 [==============================] - 78s 200ms/step - loss: 0.1426 - accuracy: 0.9493 - val_loss: 0.0592 - val_accuracy: 0.9765\n",
      "Epoch 45/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.1492 - accuracy: 0.9491 - val_loss: 0.0602 - val_accuracy: 0.9762\n",
      "Epoch 46/1000\n",
      "388/388 [==============================] - 75s 192ms/step - loss: 0.1392 - accuracy: 0.9524 - val_loss: 0.0584 - val_accuracy: 0.9790\n",
      "Epoch 47/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.1358 - accuracy: 0.9520 - val_loss: 0.0608 - val_accuracy: 0.9742\n",
      "Epoch 48/1000\n",
      "388/388 [==============================] - 72s 184ms/step - loss: 0.1327 - accuracy: 0.9539 - val_loss: 0.0573 - val_accuracy: 0.9776\n",
      "Epoch 49/1000\n",
      "388/388 [==============================] - 74s 189ms/step - loss: 0.1338 - accuracy: 0.9538 - val_loss: 0.0542 - val_accuracy: 0.9794\n",
      "Epoch 50/1000\n",
      "388/388 [==============================] - 75s 192ms/step - loss: 0.1336 - accuracy: 0.9528 - val_loss: 0.0553 - val_accuracy: 0.9802\n",
      "Epoch 51/1000\n",
      "388/388 [==============================] - 75s 192ms/step - loss: 0.1340 - accuracy: 0.9552 - val_loss: 0.0565 - val_accuracy: 0.9780\n",
      "Epoch 52/1000\n",
      "388/388 [==============================] - 76s 194ms/step - loss: 0.1258 - accuracy: 0.9564 - val_loss: 0.0535 - val_accuracy: 0.9795\n",
      "Epoch 53/1000\n",
      "388/388 [==============================] - 73s 187ms/step - loss: 0.1255 - accuracy: 0.9561 - val_loss: 0.0489 - val_accuracy: 0.9814\n",
      "Epoch 54/1000\n",
      "388/388 [==============================] - 71s 181ms/step - loss: 0.1256 - accuracy: 0.9561 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 55/1000\n",
      "388/388 [==============================] - 71s 181ms/step - loss: 0.1225 - accuracy: 0.9581 - val_loss: 0.0552 - val_accuracy: 0.9791\n",
      "Epoch 56/1000\n",
      "388/388 [==============================] - 71s 181ms/step - loss: 0.1195 - accuracy: 0.9581 - val_loss: 0.0539 - val_accuracy: 0.9790\n",
      "Epoch 57/1000\n",
      "388/388 [==============================] - 69s 178ms/step - loss: 0.1188 - accuracy: 0.9603 - val_loss: 0.0514 - val_accuracy: 0.9807\n",
      "Epoch 58/1000\n",
      "388/388 [==============================] - 71s 182ms/step - loss: 0.1131 - accuracy: 0.9604 - val_loss: 0.0522 - val_accuracy: 0.9793\n",
      "Epoch 59/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1134 - accuracy: 0.9596 - val_loss: 0.0481 - val_accuracy: 0.9812\n",
      "Epoch 60/1000\n",
      "388/388 [==============================] - 70s 180ms/step - loss: 0.1230 - accuracy: 0.9581 - val_loss: 0.0468 - val_accuracy: 0.9839\n",
      "Epoch 61/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1128 - accuracy: 0.9601 - val_loss: 0.0441 - val_accuracy: 0.9846\n",
      "Epoch 62/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1119 - accuracy: 0.9610 - val_loss: 0.0451 - val_accuracy: 0.9822\n",
      "Epoch 63/1000\n",
      "388/388 [==============================] - 71s 183ms/step - loss: 0.1146 - accuracy: 0.9608 - val_loss: 0.0457 - val_accuracy: 0.9824\n",
      "Epoch 64/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1059 - accuracy: 0.9640 - val_loss: 0.0430 - val_accuracy: 0.9838\n",
      "Epoch 65/1000\n",
      "388/388 [==============================] - 70s 180ms/step - loss: 0.1059 - accuracy: 0.9638 - val_loss: 0.0438 - val_accuracy: 0.9827\n",
      "Epoch 66/1000\n",
      "388/388 [==============================] - 69s 177ms/step - loss: 0.1083 - accuracy: 0.9632 - val_loss: 0.0432 - val_accuracy: 0.9839\n",
      "Epoch 67/1000\n",
      "388/388 [==============================] - 70s 180ms/step - loss: 0.1088 - accuracy: 0.9629 - val_loss: 0.0424 - val_accuracy: 0.9862\n",
      "Epoch 68/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1013 - accuracy: 0.9644 - val_loss: 0.0417 - val_accuracy: 0.9842\n",
      "Epoch 69/1000\n",
      "388/388 [==============================] - 70s 179ms/step - loss: 0.1021 - accuracy: 0.9652 - val_loss: 0.0374 - val_accuracy: 0.9861\n",
      "Epoch 70/1000\n",
      "388/388 [==============================] - 72s 185ms/step - loss: 0.1009 - accuracy: 0.9657 - val_loss: 0.0412 - val_accuracy: 0.9852\n",
      "Epoch 71/1000\n",
      "388/388 [==============================] - 69s 177ms/step - loss: 0.0925 - accuracy: 0.9670 - val_loss: 0.0383 - val_accuracy: 0.9846\n",
      "Epoch 72/1000\n",
      "388/388 [==============================] - 70s 181ms/step - loss: 0.1007 - accuracy: 0.9646 - val_loss: 0.0383 - val_accuracy: 0.9856\n",
      "Epoch 73/1000\n",
      "388/388 [==============================] - 70s 181ms/step - loss: 0.1015 - accuracy: 0.9654 - val_loss: 0.0388 - val_accuracy: 0.9860\n",
      "Epoch 74/1000\n",
      "388/388 [==============================] - 74s 191ms/step - loss: 0.0988 - accuracy: 0.9665 - val_loss: 0.0392 - val_accuracy: 0.9858\n",
      "Epoch 75/1000\n",
      "388/388 [==============================] - 73s 188ms/step - loss: 0.0964 - accuracy: 0.9669 - val_loss: 0.0395 - val_accuracy: 0.9853\n",
      "Epoch 76/1000\n",
      "388/388 [==============================] - 75s 192ms/step - loss: 0.0948 - accuracy: 0.9688 - val_loss: 0.0386 - val_accuracy: 0.9876\n",
      "Epoch 77/1000\n",
      "144/388 [==========>...................] - ETA: 41s - loss: 0.0928 - accuracy: 0.9685"
     ]
    }
   ],
   "source": [
    "model.fit(train,\n",
    "    epochs = epochs,\n",
    "    validation_data = test,\n",
    "    callbacks= [\n",
    "        callbacks.EarlyStopping(\n",
    "            monitor = 'val_loss',\n",
    "            patience = patience,\n",
    "            verbose = 1\n",
    "        ),\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath = model_path,\n",
    "            save_weights_only = False,\n",
    "            monitor = 'loss',\n",
    "            mode = 'min',\n",
    "            save_best_only = True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
